# Papers
This repo contains some of the papers I have read in the past or plan in read in the future. They will be organized in groups of same major topic. In the case a paper was published at a conference, I will write it down. 

## General
### 2020
[Implicit Geometric Regularization for Learning Shapes](https://arxiv.org/abs/2002.10099)  
[LaProp: a Better Way to Combine Momentum with Adaptive Gradient](https://arxiv.org/abs/2002.04839)  

### 2019
[diffGrad: An Optimization Method for Convolutional Neural Networks](https://arxiv.org/abs/1909.11015v3)  
[Lookahead Optimizer: k steps forward, 1 step back](https://arxiv.org/abs/1907.08610v2) on NIPS 2019  

### 2018
[Amortized Inference Regularization](http://papers.nips.cc/paper/7692-amortized-inference-regularization) on NIPS 2018

## Variational Inference
### 2020
[BasisVAE: Translation-invariant feature-level clustering with Variational Autoencoders](https://arxiv.org/abs/2003.03462v1) on AISTATS 2020  

### 2019
[BIVA: A Very Deep Hierarchy of Latent Variables for Generative Modeling](https://arxiv.org/abs/1902.02102) on NeurIPS 2019  
[The Usual Suspects? Reassessing Blame for VAE Posterior Collapse](https://arxiv.org/abs/1912.10702) on ICLR 2020  
[Lagging Inference Networks and Posterior Collapse in Variational Autoencoders](https://arxiv.org/abs/1901.05534) on ICLR 2019  
[Understanding Posterior Collapse in Generative Latent Variable Models](https://openreview.net/forum?id=r1xaVLUYuE) on ICLR 2019  
[Amortized Population Gibbs Samplers with Neural Sufficient Statistics](https://arxiv.org/abs/1911.01382v1)  
[Amortized Population Gibbs Samplers with Neural Sufficient Statistics](https://arxiv.org/abs/1911.01382v1) on ICLR 2019  
[Hierarchical Importance Weighted Autoencoders](https://arxiv.org/abs/1905.04866v1) on ICML 2019   
[Block Neural Autoregressive Flow](https://arxiv.org/abs/1904.04676v1)  
[Variationally Inferred Sampling Through a Refined Bound for Probabilistic Programs](https://arxiv.org/abs/1908.09744v3)  
[Resampled Priors for Variational Autoencoders](https://arxiv.org/abs/1810.11428v2) on AISTATS 2019  
[Revisiting Auxiliary Latent Variables in Generative Models](https://openreview.net/forum?id=SyxPVLUYdE) on ICLR 2019 (workshop)  
[Importance Weighted Hierarchical Variational Inference](https://arxiv.org/abs/1905.03290v1)  
[Doubly Semi-Implicit Variational Inference](https://arxiv.org/abs/1810.02789v2) on AISTATS 2019  
[Unbiased Implicit Variational Inference](https://arxiv.org/abs/1808.02078v3) on AISTATS 2019  
[Learning Hierarchical Priors in VAEs](https://arxiv.org/abs/1905.04982v5) on NeurIPS 2019  
[Annealed Importance Weighted Auto-Encoders](https://arxiv.org/abs/1906.04904)  
[Learning Hierarchical Priors in VAEs](https://arxiv.org/abs/1905.04982) on NeurIPS 2019)  
[Structured Semi-Implicit Variational Inference](https://openreview.net/forum?id=HkxStk34Kr)  

### 2018
[A Hierarchical Latent Structure for Variational Conversation Modeling](https://arxiv.org/abs/1804.03424)  
[Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects](http://papers.nips.cc/paper/8079-sequential-attend-infer-repeat-generative-modelling-of-moving-objects.pdf) on NeurIPS 2018  
[Variational Autoencoders Pursue PCA Directions (by Accident)](https://arxiv.org/abs/1812.06775) on CVPR 2019  
[Preventing Posterior Collapse with delta-VAEs](https://openreview.net/forum?id=BJe0Gn0cY7) on ICLR 2019  
[Hyperspherical Variational Auto-Encoders](https://arxiv.org/abs/1804.00891)  
[Variational Rejection Sampling](https://arxiv.org/abs/1804.01712v1) on AISTATS 2018  
[VAE with a VampPrior](https://arxiv.org/abs/1705.07120v5) on AISTATS 2018  
[Importance Weighting and Variational Inference](https://arxiv.org/abs/1808.09034) on NIPS 2018  
[Semi-Implicit Variational Inference](https://arxiv.org/abs/1805.11183v1) on ICML 2018  
[Variational Autoencoder with Implicit Optimal Priors](https://arxiv.org/abs/1809.05284v1)  
[Variational Saccading: Efficient Inference for Large Resolution Images](https://arxiv.org/abs/1812.03170) on BMVC 2019  
[Semi-Amortized Variational Autoencoders](https://arxiv.org/abs/1802.02550v7) on ICML 2018  
[Iterative Amortized Inference](https://arxiv.org/abs/1807.09356) on ICML 2018  
[Improving Explorability in Variational Inference with Annealed Variational Objectives](https://arxiv.org/abs/1809.01818) on NIPS 2018  
[Implicit Reparameterization Gradients](https://arxiv.org/abs/1805.08498) on NIPS 2018  

### 2017
[Adversarial Variational Bayes: Unifying Variational Autoencoders and Generative Adversarial Networks](https://arxiv.org/abs/1701.04722) on ICML 2017  
[Variational Inference using Implicit Distributions](https://arxiv.org/abs/1702.08235)  

### 2016
[Attend, Infer, Repeat: Fast Scene Understanding with Generative Models](https://arxiv.org/abs/1603.08575) on CVPR 2016  
[Hierarchical Variational Models](https://arxiv.org/abs/1511.02386) on JMLR 2016  
[The Generalized Reparameterization Gradient](https://arxiv.org/abs/1610.02287) on NIPS 2016  
[Reparameterization Gradients through Acceptance-Rejection Sampling Algorithms](https://arxiv.org/abs/1610.05683) on AISTATS 2017  
[Automatic Differentiation Variational Inference](https://arxiv.org/abs/1603.00788) on JMLR 2016  

### 2013
[Black Box Variational Inference](https://arxiv.org/abs/1401.0118) on AISTATS 2014  

## Neural Attention
### 2019
[Recurrent Layer Attention Network](https://openreview.net/forum?id=Bke5aJBKvH) on ICLR 2019  
[Expectation-Maximization Attention Networks for Semantic Segmentation](https://arxiv.org/abs/1907.13426v2) on ICCV 2019  
[Attention Augmented Convolutional Networks](https://arxiv.org/abs/1904.09925v4)  
[Attention is all you need for Videos: Self-attention based Video Summarization using Universal Transformers](https://arxiv.org/abs/1906.02792v1)  
[Is Attention Interpretable?](https://arxiv.org/abs/1906.03731v1) on ACL 2019  
[Processing Megapixel Images with Deep Attention-Sampling Models](https://arxiv.org/abs/1905.03711) on ICML 2019  
[Saccader: Improving Accuracy of Hard Attention Models for Vision](https://openreview.net/forum?id=SyxrNVSg8B) on NeurIPS 2019  

## Neural Flows
### 2020
[You say Normalizing Flows I see Bayesian Networks](https://arxiv.org/abs/2006.00866)  
[Flows for simultaneous manifold learning and density estimation](https://arxiv.org/abs/2003.13913)  
[Exact Information Bottleneck with Invertible Neural Networks: Getting the Best of Discriminative and Generative Modeling](https://arxiv.org/abs/2001.06448)  
[Latent Variable Modelling with Hyperbolic Normalizing Flows](https://arxiv.org/abs/2002.06336)  
[Stochastic Normalizing Flows](https://arxiv.org/abs/2002.09547)[1]  
[Stochastic Normalizing Flows](https://arxiv.org/abs/2002.06707)[2]  

### 2019
[Neural Spline Flows](https://arxiv.org/abs/1906.04032) on NIPS 2019  
[Learning Likelihoods with Conditional Normalizing Flows](http://arxiv.org/abs/1912.00042v1)  
[Conditional Flow Variational Autoencoders for Structured Sequence Prediction](https://openreview.net/forum?id=BklmtJBKDB)  

### 2018
[FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models](https://arxiv.org/abs/1810.01367) on ICLR 2019  
[Analyzing Inverse Problems with Invertible Neural Networks](https://arxiv.org/abs/1808.04730) on ICLR 2019  

## Neural Autoregressive Models
### 2019
[Block Neural Autoregressive Flow](https://arxiv.org/abs/1904.04676)  

### 2018
[Neural Autoregressive Flows](https://arxiv.org/abs/1804.00779) on ICML 2019 (workshop)  

### 2016
[Neural Autoregressive Distribution Estimation](https://arxiv.org/abs/1605.02226) on JMLR 2016  

### 2014
[ Neural Autoregressive Approach to Attention-based Recognition](https://www.cs.toronto.edu/~zemel/documents/preprint_ijcv_2014.pdf)
