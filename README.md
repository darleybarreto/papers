# Papers
This repo contains some of the papers I have read in the past or plan in read in the future. They will be organized in groups of same major topic. In the case a paper was published at a conference, I will write it down. 


## Variational Inference
### 2019
[Amortized Population Gibbs Samplers with Neural Sufficient Statistics](https://arxiv.org/abs/1911.01382v1)  
[Hierarchical Importance Weighted Autoencoders](https://arxiv.org/abs/1905.04866v1) on ICML 2019   
[Block Neural Autoregressive Flow](https://arxiv.org/abs/1904.04676v1)  
[Variationally Inferred Sampling Through a Refined Bound for Probabilistic Programs](https://arxiv.org/abs/1908.09744v3)  
[Resampled Priors for Variational Autoencoders](https://arxiv.org/abs/1810.11428v2) on AISTATS 2019  
[Revisiting Auxiliary Latent Variables in Generative Models](https://openreview.net/forum?id=SyxPVLUYdE) on ICLR 2019 (workshop)  
[Importance Weighted Hierarchical Variational Inference](https://arxiv.org/abs/1905.03290v1)  
[Doubly Semi-Implicit Variational Inference](https://arxiv.org/abs/1810.02789v2) on AISTATS 2019  
[Unbiased Implicit Variational Inference](https://arxiv.org/abs/1808.02078v3) on AISTATS 2019  
[Learning Hierarchical Priors in VAEs](https://arxiv.org/abs/1905.04982v5) on NeurIPS 2019  
[Annealed Importance Weighted Auto-Encoders](https://arxiv.org/abs/1906.04904)

### 2018
[Variational Rejection Sampling](https://arxiv.org/abs/1804.01712v1) on AISTATS 2018  
[VAE with a VampPrior](https://arxiv.org/abs/1705.07120v5) on AISTATS 2018  
[Importance Weighting and Variational Inference](https://arxiv.org/abs/1808.09034) on NIPS 2018  
[Semi-Implicit Variational Inference](https://arxiv.org/abs/1805.11183v1) on ICML 2018  
[Variational Autoencoder with Implicit Optimal Priors](https://arxiv.org/abs/1809.05284v1)  
[Variational Saccading: Efficient Inference for Large Resolution Images](https://arxiv.org/abs/1812.03170) on BMVC 2019  
[Semi-Amortized Variational Autoencoders](https://arxiv.org/abs/1802.02550v7) on ICML 2018  
[Iterative Amortized Inference](https://arxiv.org/abs/1807.09356) on ICML 2018  
[Improving Explorability in Variational Inference with Annealed Variational Objectives](https://arxiv.org/abs/1809.01818) on NIPS 2018  
[Implicit Reparameterization Gradients](https://arxiv.org/abs/1805.08498) on NIPS 2018

### 2017
[Adversarial Variational Bayes: Unifying Variational Autoencoders and Generative Adversarial Networks](https://arxiv.org/abs/1701.04722) on ICML 2017
[Variational Inference using Implicit Distributions](https://arxiv.org/abs/1702.08235)  

### 2016
[Hierarchical Variational Models](https://arxiv.org/abs/1511.02386) on JMLR 2016  
[The Generalized Reparameterization Gradient](https://arxiv.org/abs/1610.02287) on NIPS 2016  
[Reparameterization Gradients through Acceptance-Rejection Sampling Algorithms](https://arxiv.org/abs/1610.05683) on AISTATS 2017  
[Automatic Differentiation Variational Inference](https://arxiv.org/abs/1603.00788) on JMLR 2016  

### 2013
[Black Box Variational Inference](https://arxiv.org/abs/1401.0118) on AISTATS 2014

## Neural Attention
### 2019
[Recurrent Layer Attention Network](https://openreview.net/forum?id=Bke5aJBKvH) on ICLR 2019  
[Expectation-Maximization Attention Networks for Semantic Segmentation](https://arxiv.org/abs/1907.13426v2) on ICCV 2019  
[Attention Augmented Convolutional Networks](https://arxiv.org/abs/1904.09925v4)  
[Attention is all you need for Videos: Self-attention based Video Summarization using Universal Transformers](https://arxiv.org/abs/1906.02792v1)  
[Is Attention Interpretable?](https://arxiv.org/abs/1906.03731v1) on ACL 2019  
[Processing Megapixel Images with Deep Attention-Sampling Models](https://arxiv.org/abs/1905.03711) on ICML 2019  
[Saccader: Improving Accuracy of Hard Attention Models for Vision](https://openreview.net/forum?id=SyxrNVSg8B) on NeurIPS 2019


## Neural Autoregressive Models
### 2019
[Block Neural Autoregressive Flow](https://arxiv.org/abs/1904.04676)

### 2018
[Neural Autoregressive Flows](https://arxiv.org/abs/1804.00779) on ICML 2019 (workshop)  

### 2016
[Neural Autoregressive Distribution Estimation](https://arxiv.org/abs/1605.02226) on JMLR 2016

### 2014
[ Neural Autoregressive Approach to Attention-based Recognition](https://www.cs.toronto.edu/~zemel/documents/preprint_ijcv_2014.pdf)
